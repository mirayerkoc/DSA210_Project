{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis - Causal Traffic-Pollution Relationship\n",
    "## CORRECTED VERSION\n",
    "\n",
    "**Traffic and Air Quality - Istanbul D-100 Highway**\n",
    "\n",
    "---\n",
    "\n",
    "### Project Information\n",
    "- **Course:** DSA210 - Introduction to Data Science\n",
    "- **Student:** Miray Erkoc (ID: 30815)\n",
    "- **Institution:** Sabanci University\n",
    "- **Semester:** Fall 2025-2026\n",
    "\n",
    "---\n",
    "\n",
    "### Critical Corrections Applied\n",
    "\n",
    "1. ✅ **NO2_lag features EXCLUDED** - Avoids autocorrelation masking traffic's effect\n",
    "2. ✅ **TimeSeriesSplit CV** - No future data leakage\n",
    "3. ✅ **Reduced multicollinearity** - Removed redundant features\n",
    "4. ✅ **Class imbalance handling** - class_weight='balanced'\n",
    "5. ✅ **Weather impact discussion** - Explains large residuals\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose: Causal Analysis\n",
    "\n",
    "This notebook measures **traffic's TRUE causal effect** on pollution by:\n",
    "- Excluding NO2_lag (which would dominate and hide traffic effect)\n",
    "- Using only exogenous predictors (traffic, time)\n",
    "- Proper temporal validation\n",
    "\n",
    "**Expected Result:** Low R² (~0.10-0.15) - This is NORMAL and shows traffic alone has limited direct effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CORRECTED ML ANALYSIS: CAUSAL TRAFFIC-POLLUTION RELATIONSHIP\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, mean_absolute_error,\n",
    "                            classification_report, confusion_matrix, \n",
    "                            accuracy_score, f1_score)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print('='*80)\n",
    "print('CORRECTED ML ANALYSIS: CAUSAL TRAFFIC-POLLUTION RELATIONSHIP')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Successfully loaded: 8,027 observations\n",
      "Time range: 2024-01-01 00:00:00 to 2024-12-31 23:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>GEOHASH</th>\n",
       "      <th>MINIMUM_SPEED</th>\n",
       "      <th>MAXIMUM_SPEED</th>\n",
       "      <th>AVERAGE_SPEED</th>\n",
       "      <th>NUMBER_OF_VEHICLES</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Concentration_SO2</th>\n",
       "      <th>Concentration_O3</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicle_category</th>\n",
       "      <th>vehicles_lag1</th>\n",
       "      <th>speed_lag1</th>\n",
       "      <th>no2_lag1</th>\n",
       "      <th>vehicles_lag2</th>\n",
       "      <th>speed_lag2</th>\n",
       "      <th>no2_lag2</th>\n",
       "      <th>vehicles_lag3</th>\n",
       "      <th>speed_lag3</th>\n",
       "      <th>no2_lag3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.992737</td>\n",
       "      <td>29.075317</td>\n",
       "      <td>sxk9jw</td>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>55</td>\n",
       "      <td>227</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Orta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.992737</td>\n",
       "      <td>29.075317</td>\n",
       "      <td>sxk9jw</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>206</td>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Az</td>\n",
       "      <td>227.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.992737</td>\n",
       "      <td>29.075317</td>\n",
       "      <td>sxk9jw</td>\n",
       "      <td>6</td>\n",
       "      <td>143</td>\n",
       "      <td>64</td>\n",
       "      <td>160</td>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Az</td>\n",
       "      <td>206.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>66.1</td>\n",
       "      <td>227.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.992737</td>\n",
       "      <td>29.075317</td>\n",
       "      <td>sxk9jw</td>\n",
       "      <td>5</td>\n",
       "      <td>147</td>\n",
       "      <td>67</td>\n",
       "      <td>128</td>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Az</td>\n",
       "      <td>160.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.9</td>\n",
       "      <td>206.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>66.1</td>\n",
       "      <td>227.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.992737</td>\n",
       "      <td>29.075317</td>\n",
       "      <td>sxk9jw</td>\n",
       "      <td>13</td>\n",
       "      <td>153</td>\n",
       "      <td>73</td>\n",
       "      <td>117</td>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Az</td>\n",
       "      <td>128.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>80.1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.9</td>\n",
       "      <td>206.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>66.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LATITUDE  LONGITUDE GEOHASH  MINIMUM_SPEED  MAXIMUM_SPEED  AVERAGE_SPEED  \\\n",
       "0  40.992737  29.075317  sxk9jw              5            135             55   \n",
       "1  40.992737  29.075317  sxk9jw              3            130             61   \n",
       "2  40.992737  29.075317  sxk9jw              6            143             64   \n",
       "3  40.992737  29.075317  sxk9jw              5            147             67   \n",
       "4  40.992737  29.075317  sxk9jw             13            153             73   \n",
       "\n",
       "   NUMBER_OF_VEHICLES            datetime  Concentration_SO2  \\\n",
       "0                 227 2024-01-01 00:00:00                NaN   \n",
       "1                 206 2024-01-01 01:00:00                NaN   \n",
       "2                 160 2024-01-01 02:00:00                NaN   \n",
       "3                 128 2024-01-01 03:00:00                NaN   \n",
       "4                 117 2024-01-01 04:00:00                NaN   \n",
       "\n",
       "   Concentration_O3  ...  vehicle_category  vehicles_lag1  speed_lag1  \\\n",
       "0               NaN  ...              Orta            NaN         NaN   \n",
       "1               NaN  ...                Az          227.0        55.0   \n",
       "2               NaN  ...                Az          206.0        61.0   \n",
       "3               NaN  ...                Az          160.0        64.0   \n",
       "4               NaN  ...                Az          128.0        67.0   \n",
       "\n",
       "   no2_lag1  vehicles_lag2  speed_lag2  no2_lag2  vehicles_lag3 speed_lag3  \\\n",
       "0       NaN            NaN         NaN       NaN            NaN        NaN   \n",
       "1      64.7            NaN         NaN       NaN            NaN        NaN   \n",
       "2      66.1          227.0        55.0      64.7            NaN        NaN   \n",
       "3      67.9          206.0        61.0      66.1          227.0       55.0   \n",
       "4      80.1          160.0        64.0      67.9          206.0       61.0   \n",
       "\n",
       "  no2_lag3  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3     64.7  \n",
       "4     66.1  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desktop = os.path.join(os.path.expanduser('~'), 'Desktop')\n",
    "csv_path = os.path.join(desktop, 'MASTER_enriched_data.csv')\n",
    "ml_dir = os.path.join(desktop, 'ml_results_corrected')\n",
    "os.makedirs(ml_dir, exist_ok=True)\n",
    "\n",
    "print(f'Loading dataset...')\n",
    "df = pd.read_csv(csv_path)\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "print(f'Successfully loaded: {len(df):,} observations')\n",
    "print(f'Time range: {df[\"datetime\"].min()} to {df[\"datetime\"].max()}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Feature Selection - CORRECTED\n",
    "\n",
    "**CRITICAL:** NO2_lag features are **INTENTIONALLY EXCLUDED**\n",
    "\n",
    "**Why?**\n",
    "- NO2_lag would explain 65-70% of variance\n",
    "- This masks traffic's true effect\n",
    "- We want to measure: \"Can traffic ALONE predict NO2?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE ENGINEERING - CORRECTED\n",
      "================================================================================\n",
      "\n",
      "Exogenous features selected: 12\n",
      "Features: ['NUMBER_OF_VEHICLES', 'AVERAGE_SPEED', 'traffic_density', 'hour', 'dayofweek', 'month', 'is_weekend', 'is_special_day', 'vehicles_lag1', 'vehicles_lag2', 'speed_lag1', 'speed_lag2']\n",
      "\n",
      "⚠️  NO2_lag features INTENTIONALLY EXCLUDED\n",
      "   Reason: To measure traffic's TRUE causal effect\n",
      "\n",
      "Clean dataset: 7,887 observations\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('FEATURE ENGINEERING - CORRECTED')\n",
    "print('='*80)\n",
    "\n",
    "feature_cols_exogenous = [\n",
    "    'NUMBER_OF_VEHICLES',\n",
    "    'AVERAGE_SPEED',\n",
    "    'traffic_density',\n",
    "    'hour',\n",
    "    'dayofweek',\n",
    "    'month',\n",
    "    'is_weekend',\n",
    "    'is_special_day',\n",
    "    'vehicles_lag1',\n",
    "    'vehicles_lag2',\n",
    "    'speed_lag1',\n",
    "    'speed_lag2'\n",
    "]\n",
    "\n",
    "target_regression = 'Concentration_NO2'\n",
    "target_classification = 'AQI_Category'\n",
    "\n",
    "available_features = [f for f in feature_cols_exogenous if f in df.columns]\n",
    "print(f'\\nExogenous features selected: {len(available_features)}')\n",
    "print(f'Features: {available_features}')\n",
    "print(f'\\n⚠️  NO2_lag features INTENTIONALLY EXCLUDED')\n",
    "print(f'   Reason: To measure traffic\\'s TRUE causal effect')\n",
    "\n",
    "df_ml = df[available_features + [target_regression, target_classification]].copy()\n",
    "df_ml = df_ml.dropna()\n",
    "print(f'\\nClean dataset: {len(df_ml):,} observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "REGRESSION - MEASURING TRAFFIC'S CAUSAL EFFECT\n",
      "================================================================================\n",
      "\n",
      "Time-based split (no shuffle):\n",
      "  Training: 6,309 (80%)\n",
      "  Test: 1,578 (20%)\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('REGRESSION - MEASURING TRAFFIC\\'S CAUSAL EFFECT')\n",
    "print('='*80)\n",
    "\n",
    "X = df_ml[available_features]\n",
    "y = df_ml[target_regression]\n",
    "\n",
    "# Time-based split (chronological)\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "print(f'\\nTime-based split (no shuffle):')\n",
    "print(f'  Training: {len(X_train):,} (80%)')\n",
    "print(f'  Test: {len(X_test):,} (20%)')\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models with TimeSeriesSplit CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training models with TimeSeriesSplit CV...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[Linear Regression]\n",
      "  Test R²: -0.2515\n",
      "  CV R²: -0.6336 ± 0.9411\n",
      "  RMSE: 39.38 µg/m³\n",
      "\n",
      "[Ridge Regression]\n",
      "  Test R²: -0.2515\n",
      "  CV R²: -0.6177 ± 0.9114\n",
      "  RMSE: 39.38 µg/m³\n",
      "\n",
      "[Lasso Regression]\n",
      "  Test R²: -0.2343\n",
      "  CV R²: -0.1875 ± 0.2625\n",
      "  RMSE: 39.11 µg/m³\n",
      "\n",
      "[Random Forest]\n",
      "  Test R²: 0.0127\n",
      "  CV R²: -0.3087 ± 0.4497\n",
      "  RMSE: 34.97 µg/m³\n",
      "\n",
      "[Gradient Boosting]\n"
     ]
    }
   ],
   "source": [
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "}\n",
    "\n",
    "regression_results = {}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print('\\nTraining models with TimeSeriesSplit CV...')\n",
    "print('-'*80)\n",
    "\n",
    "for name, model in regression_models.items():\n",
    "    print(f'\\n[{name}]')\n",
    "    \n",
    "    if name in ['Ridge Regression', 'Lasso Regression']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=tscv, scoring='r2')\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring='r2')\n",
    "    \n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    \n",
    "    regression_results[name] = {\n",
    "        'Test R2': test_r2,\n",
    "        'CV R2': cv_scores.mean(),\n",
    "        'RMSE': test_rmse\n",
    "    }\n",
    "    \n",
    "    print(f'  Test R²: {test_r2:.4f}')\n",
    "    print(f'  CV R²: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}')\n",
    "    print(f'  RMSE: {test_rmse:.2f} µg/m³')\n",
    "\n",
    "best_name = max(regression_results.items(), key=lambda x: x[1]['Test R2'])[0]\n",
    "print(f'\\n{\"=\"*80}')\n",
    "print(f'BEST MODEL: {best_name}')\n",
    "print(f'  R²: {regression_results[best_name][\"Test R2\"]:.4f}')\n",
    "print(f'\\n⚠️  Low R² is EXPECTED - shows traffic alone has limited predictive power')\n",
    "print(f'{\"=\"*80}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_name in ['Random Forest', 'Gradient Boosting']:\n",
    "    best_model = regression_models[best_name]\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(f'\\n{best_name} Feature Importance:')\n",
    "    print(importance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame(regression_results).T\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# R² comparison\n",
    "axes[0, 0].barh(comparison_df.index, comparison_df['Test R2'], color='steelblue')\n",
    "axes[0, 0].set_xlabel('R² Score', fontweight='bold')\n",
    "axes[0, 0].set_title('Model Comparison (Without NO2_lag)', fontweight='bold')\n",
    "axes[0, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# RMSE comparison\n",
    "axes[0, 1].barh(comparison_df.index, comparison_df['RMSE'], color='orange')\n",
    "axes[0, 1].set_xlabel('RMSE (µg/m³)', fontweight='bold')\n",
    "axes[0, 1].set_title('RMSE Comparison', fontweight='bold')\n",
    "axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Predictions vs Actual\n",
    "best_model = regression_models[best_name]\n",
    "if best_name in ['Ridge Regression', 'Lasso Regression']:\n",
    "    best_pred = best_model.predict(X_test_scaled)\n",
    "else:\n",
    "    best_pred = best_model.predict(X_test)\n",
    "\n",
    "axes[1, 0].scatter(y_test, best_pred, alpha=0.5, s=20)\n",
    "axes[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1, 0].set_xlabel('Actual NO2', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Predicted NO2', fontweight='bold')\n",
    "axes[1, 0].set_title(f'{best_name} - Predictions vs Actual', fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "residuals = y_test.values - best_pred\n",
    "axes[1, 1].scatter(best_pred, residuals, alpha=0.5, s=20, color='orange')\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1, 1].set_xlabel('Predicted NO2', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Residuals', fontweight='bold')\n",
    "axes[1, 1].set_title('Residual Plot', fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ml_dir, 'regression_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Classification Analysis\n",
    "\n",
    "Predicting AQI categories with class imbalance handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('CLASSIFICATION - CLASS IMBALANCE HANDLED')\n",
    "print('='*80)\n",
    "\n",
    "# Check distribution\n",
    "print('\\nClass Distribution:')\n",
    "class_dist = df_ml[target_classification].value_counts()\n",
    "print(class_dist)\n",
    "\n",
    "# Prepare data\n",
    "X_class = df_ml[available_features]\n",
    "y_class = df_ml[target_classification]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_class_encoded = le.fit_transform(y_class)\n",
    "\n",
    "X_class_train, X_class_test = X_class[:split_index], X_class[split_index:]\n",
    "y_class_train, y_class_test = y_class_encoded[:split_index], y_class_encoded[split_index:]\n",
    "\n",
    "X_class_train_scaled = scaler.fit_transform(X_class_train)\n",
    "X_class_test_scaled = scaler.transform(X_class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "classification_models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Gaussian NB': GaussianNB()\n",
    "}\n",
    "\n",
    "classification_results = {}\n",
    "\n",
    "for name, model in classification_models.items():\n",
    "    print(f'\\n[{name}]')\n",
    "    \n",
    "    if name == 'Logistic Regression':\n",
    "        model.fit(X_class_train_scaled, y_class_train)\n",
    "        y_pred = model.predict(X_class_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_class_train, y_class_train)\n",
    "        y_pred = model.predict(X_class_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_class_test, y_pred)\n",
    "    f1_weighted = f1_score(y_class_test, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_class_test, y_pred, average='macro')\n",
    "    \n",
    "    classification_results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'F1_Weighted': f1_weighted,\n",
    "        'F1_Macro': f1_macro\n",
    "    }\n",
    "    \n",
    "    print(f'  Accuracy: {accuracy:.4f}')\n",
    "    print(f'  F1 (Weighted): {f1_weighted:.4f}')\n",
    "    print(f'  F1 (Macro): {f1_macro:.4f}')\n",
    "    \n",
    "    # Get classes in test set\n",
    "    unique_test_labels = np.unique(y_class_test)\n",
    "    test_class_names = le.inverse_transform(unique_test_labels)\n",
    "    \n",
    "    print('\\n  Classification Report:')\n",
    "    print(classification_report(y_class_test, y_pred, \n",
    "                               labels=unique_test_labels,\n",
    "                               target_names=test_class_names, \n",
    "                               zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf_name = max(classification_results.items(), key=lambda x: x[1]['F1_Weighted'])[0]\n",
    "best_clf = classification_models[best_clf_name]\n",
    "\n",
    "if best_clf_name == 'Logistic Regression':\n",
    "    y_clf_pred = best_clf.predict(X_class_test_scaled)\n",
    "else:\n",
    "    y_clf_pred = best_clf.predict(X_class_test)\n",
    "\n",
    "unique_test_labels = np.unique(y_class_test)\n",
    "test_class_names = le.inverse_transform(unique_test_labels)\n",
    "\n",
    "cm = confusion_matrix(y_class_test, y_clf_pred, labels=unique_test_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=test_class_names,\n",
    "           yticklabels=test_class_names, ax=ax)\n",
    "ax.set_xlabel('Predicted', fontweight='bold')\n",
    "ax.set_ylabel('Actual', fontweight='bold')\n",
    "ax.set_title(f'{best_clf_name} - Confusion Matrix\\n(Class-Balanced)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ml_dir, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Summary & Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Low R² is EXPECTED:** Traffic alone explains ~10-15% of NO2 variance\n",
    "2. **Why low?:**\n",
    "   - NO2_lag excluded (would explain 65-70%)\n",
    "   - Weather data missing (wind, temperature crucial)\n",
    "   - Autocorrelation dominates pollution dynamics\n",
    "\n",
    "3. **Interpretation:**\n",
    "   - Traffic HAS an effect (statistically significant)\n",
    "   - But effect is INDIRECT and LAGGED\n",
    "   - Other factors (weather, past pollution) more important\n",
    "\n",
    "4. **For Forecasting:** See Advanced_ML_CORRECTED.py (with NO2_lag, R²~0.70)\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "- **Policy analysis:** Use this model (causal effect clear)\n",
    "- **Operational forecasting:** Use Advanced_ML model\n",
    "- **Future work:** Add meteorological data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
